
-  [NeurIPS Data-Centric AI Workshop](http://datacentricai.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-937HVjS9dyctH-ENvgGHFrom09UnGuRjiF6b-zUvPUkGH136MzvI6qWOdnjjuMk7Ynr1J5)이라는 워크숍이 12월 14일에 온라인으로 열림

  - 이 워크숍은 AI의 관련된 것이며 data collection/generation, data labeling, data preprocess/augmentation, data quality evaluation, data debt, and data governance등등을 얘기함

- 생각해보면 좋을 만한 질문
  - 고품질 데이터 소싱을 가속화할 수 있는 알고리즘 또는 툴은 무엇입니까?
  - 일관성 없이 레이블이 지정된 데이터를 식별할 수 있는 알고리즘 또는 도구는 무엇입니까?
  - 데이터 품질을 보다 체계적으로 개선할 수 있는 일반적인 설계 원칙은 무엇입니까?
  - 실무자가 오류 분석을 보다 효율적으로 수행하는 데 도움이 될 수 있는 툴은 무엇입니까?
  - 예를 들어, 데이터 엔지니어링이 어떻게 책임 있는 AI를 발전시켜 공정성을 보장하고 훈련된 모델의 편향을 최소화할 수 있는가?

---

![climate change](https://dl-staging-website.ghost.io/content/images/2021/09/WEATHER.gif)

## 1. Getting a Jump on Climate Change
- 스타트업이 기후변화가 글로벌 산업에 어떤 영향을 줄지 예 -> 지구온난화에 따른 위험을 관리하는 것을 돕는 신경망 훈련

- 환경 데이터 <-> 원자재 가격, 소비패턴, 수출입 데이터 ==>상호작용을 모델링 ==> 통찰력을 판매
  - ClimateAI(2017, 샌프란시스코) : 단기예측 기후 시뮬레이션 생성 => 농작물이 어떻게 생산될지 예측
    > ex) 호주의 일부 지역에 평균보다 높은 강수량 예측: 5 ~ 10%  매출 증가 예측

  - Gro Intelligence(2014, 뉴욕): 위성사진 + 강수보고서.etc 분석==> 미래의 가뭄, 홍수등의 극한 기상상황을 예측-> 농산물에 미치는 영향을 분석
    > ex) 미국의 대기업이 고객임
    
  - One Concern : 구글 스트리트 뷰 + 위성사진등을 분석 -> 고객이 건물, 도로 및 기타 인프라에서 기후 변화로 인한 재해 대응을 계획 및 실행 할 수 있도록 지원

- 기업들은 미래의 위험을 위해 기후변화를 주의깊게 보고있음

- 왜 우리는 연구해야 하는지? 올해 있었던 전세계적인 이상기후들을 통해 AI 기반 예측 -> 기업의 자산과 수익을 보호 가능 + 향후 추가 영향을 대비 가능

- AI가 기후 재해 비용을 계산 = 현실적인 위험을 측정가능 (대기 탄소 배출)


## 2. AI Sales Closing In on $500 Billion
- 인공지능산업이 앞으로 굉장히 창창하다.
- AI 소프트웨어, 하드웨어, 서비스의 전세계 매출이 굉장히 높으며(3,418억 달러), 작년의 추정치보다도 월등히 상승한 것이며, 2024년에는 5000억 달러를 돌파할 것으로 예상됨
- 위에서 얘기했다 싶이 인공지능 산업은 소프웨어와 하드웨어, 서비스등으로 나눠서 생각해 볼 수 있으며, 이 세가지 분야가 각각 다 발전 가능성이 높다.
   - 그중에서도 소프트웨어 산업이 전체 AI 산업에서 88%로 가장높고 가장 빠르게 성장할 것으로 예상됨

## 3. Perceptrons Are All You Need (About gMLP)
- Hanxiao Liu and colleagues at Google Brain가 gated multi-layer perceptron (gMLP)를 개발함
- gMLP = transformer, 일부 언어와 시각작업을 수행하는 간단한 아키텍처(=모델)
- transformer : 다양한 입력 값(데이터)을 처리하는 모델들을 의미
  - 바닐라 신경망(vanilla neural network = 다층 퍼셉트론(multi-layer perceptron))이나 자기 주의 메커니즘(self-attention mechanism)를 이용하여 입력 시퀀스를 처리
  - 바닐라 신경망(old를 대표함): 주어진 토큰의 벡터 표현(ex, 텍스트의 단어나 이미지의 픽셀) 안에서 각 요소간의 관계에 대해 작동
  - 자기 주장 메커니즘(new를 대표함) : 시퀀스에서 각 토큰 간의 관계를 학습
    - 시퀀스 길이가 고정된 경우 바닐라 신경망도 이 과정 수행 가능
- 저자들(만든사람들)은 시퀀스의 길이를 고정 & 시퀀스에서 가장 중요하지 않은 부분을 걸러내기 위해 게이트 장치를 추가 =>주의깊게 봐야할 것을 재할당 (gating unit의 역할)
- 작동방식 : 
  - 텍스트 데이터 베이스인 [C4](https://paperswithcode.com/dataset/c4)의 영어버전에서 누락된 단어를 예측하도록 훈련
  - [SST-2](https://paperswithcode.com/dataset/sst)의 영화리뷰에서 발췌한 것으로 표현된 긍정적 감정과 부정적 감정을 분류하도록 미세 조정함
  - 이미지 데이터는 이미지 패치를 토큰으로 사용하여 [ImageNet](https://image-net.org/static_files/papers/imagenet_cvpr09.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-937HVjS9dyctH-ENvgGHFrom09UnGuRjiF6b-zUvPUkGH136MzvI6qWOdnjjuMk7Ynr1J5)에서 교육

![image](https://user-images.githubusercontent.com/88295944/133104534-973902ef-c197-4076-81b9-9b52b0da78a2.png)

- 이 모델은 입력 시퀀스를 일련의 gMLP 블록에 전달 -> 각 블록에는 바닐라 신경망이 포함 -> 게이팅 유닛과 또 다른 바닐라 신경망이 포함
- 바닐라 신경망은 요소 간의 관계를 찾기 위해 각 토큰의 768 요소 벡터 표현을 개별적으로 처리
- 게이팅 유닛은 출력에 거의 영향을 미치지 않게 하기 위해서 입력값의 일부를 효과적으로 줄임.
  - 만약 만약 벡터안에 값이 0에 가까우면 연관된 입력값이 0에 가깝게 만듬 -> 이것을 학습한 벡터와 입력값을 곱함
- 각각의 소프트 맥스레이어들은 다음 단어를 예측하는 C4, 감정을 분류하는 SST-2, ImageNet을 분류하는 것을 학습

- <b>결과(gMLP)</b>
  - 이 테스트에서 널리 사용되는 변압기 기반 언어 모델 BERT만큼 대략적으로 수행
<table>
  <th>
    <tr>
            <td>Name</td>
            <td>BERT</td>
            <td>gMLP</td>
    </tr>
   <th>
         <tr>
            <td>난해도(C4)</td>
            <td>4.17</td>
            <td>4.28</td>
    </tr>
         <tr>
            <td>정확도(SST-2)</td>
            <td>93.8</td>
            <td>94.2</td>
     </tr>
      <tr>
            <td>정확도(ImgN)</td>
            <td>81.8</td>
            <td>81.6</td>
    </tr>
</table>

- 왜 중요한지? 이모델은 구식 아키텍처에 기반한 대안이며 자기 주의 메커니즘(Self-attention)과 같은 새로운 기술의 성능의 근접하거나 초과하는 모델을 만들수 있다!
- 새로운 기술개발도 좋지만 예전모델을 주의깊게(attention!)보며 더 나은 것을 찾는것도 좋은 방법이다!


- <b>Summary</b> : vanilla NN은 옛날 인공신경 모델 + gating unit이라는 기능추가 => gMLP => New 모델인 BERT와 비교해도 뒤지지 않는다! 새로운거 만드는 것도 좋지만 예전거 다듬어서 써보는건 어때?


## 4. Solar System
- 천문학자들이 딥러닝을 태양의 초점을 맞추기 위해서 사용함


[The Batch_2021_09_09](https://read.deeplearning.ai/the-batch/issue-108/)  
[번역 및 설명해주신 스터디 혜민님 링크](https://github.com/8maccaron8/TIL/blob/main/Today_I_learned/The_Batch/20210909.md)