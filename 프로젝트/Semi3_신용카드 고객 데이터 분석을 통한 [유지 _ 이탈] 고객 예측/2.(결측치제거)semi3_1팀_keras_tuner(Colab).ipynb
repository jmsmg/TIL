{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "semi3_keras_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTuOBLppfF9s"
      },
      "source": [
        "### * \\[important] This notebook is **only for Colab-execution**, please use colaboratory to test following codes.\n",
        "### * \\[important] Change runtime type to GPU first & execute following cells\n",
        "### * Official Github repository & documents @ https://github.com/keras-team/keras-tuner\n",
        "### * Keras-tuner Basic tutorial (TF official document) @ https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCn9n7sKfeZQ"
      },
      "source": [
        "<br>\n",
        "\n",
        "## 1. Install Keras-Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "528U3VTVScOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01af2cf9-fb5f-4937-b61b-84a89c684fd4"
      },
      "source": [
        "!pip install keras-tuner==1.0.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner==1.0.2\n",
            "  Downloading keras-tuner-1.0.2.tar.gz (62 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (21.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.2) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner==1.0.2) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.2) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner==1.0.2) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-py3-none-any.whl size=78935 sha256=dedde08a7940edc84efa25d10bdd4aef5297f0bbb0201daf457a6a259ce2f951\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/e2/80/7fe373cad54ad22b06d0d6204cbc29cead9e69bb2680327775\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15355 sha256=3485243adc42d397dcbfc78635c15f2cdcf2cb6ff044fdee464a82c3c466e590\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIUmMtfJqVMx",
        "outputId": "afab9d66-0d81-496c-88cb-05b34e7d222d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "\n",
        "print(tf.__version__)\n",
        "print(kt.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87pBzHlt2_wk"
      },
      "source": [
        "# from tensorflow.keras import datasets, Sequential, utils\n",
        "# from tensorflow.keras.layers import Flatten, Conv2D, Dense, Dropout\n",
        "# from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc2nMTlrjAUW"
      },
      "source": [
        "<br>\n",
        "\n",
        "## 3. Bayesian HPO with Keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-21T05:02:34.435129Z",
          "start_time": "2021-07-21T05:02:30.955049Z"
        },
        "id": "ATb8bn-ZayvO"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "from tensorflow.keras import datasets, Sequential, utils, layers, models, optimizers, losses\n",
        "# from tensorflow.keras.layers import Flatten, Conv2D, Dense, Dropout\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import kerastuner as kt\n",
        "import numpy as np\n",
        "import IPython\n",
        "\n",
        "import copy\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 시각화\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# 결측치\n",
        "import missingno as msno\n",
        "\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn import model_selection, linear_model\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "# 파이프라인\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Import libraries for resampling\n",
        "import sklearn.neighbors._base"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "MJHJnDP26fpf",
        "outputId": "ad9fcec8-3d4a-4bfa-987c-beebdea4fbf3"
      },
      "source": [
        "data_df = pd.read_csv('filename.csv', index_col=0)\n",
        "data_df.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Attrition_Flag</th>\n",
              "      <th>Customer_Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Dependent_count</th>\n",
              "      <th>Education_Level</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Income_Category</th>\n",
              "      <th>Card_Category</th>\n",
              "      <th>Months_on_book</th>\n",
              "      <th>Total_Relationship_Count</th>\n",
              "      <th>Months_Inactive_12_mon</th>\n",
              "      <th>Contacts_Count_12_mon</th>\n",
              "      <th>Credit_Limit</th>\n",
              "      <th>Total_Revolving_Bal</th>\n",
              "      <th>Avg_Open_To_Buy</th>\n",
              "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
              "      <th>Total_Trans_Amt</th>\n",
              "      <th>Total_Trans_Ct</th>\n",
              "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
              "      <th>Avg_Utilization_Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>12691.0</td>\n",
              "      <td>777</td>\n",
              "      <td>11914.0</td>\n",
              "      <td>1.335</td>\n",
              "      <td>1144</td>\n",
              "      <td>42</td>\n",
              "      <td>1.625</td>\n",
              "      <td>0.061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>864</td>\n",
              "      <td>7392.0</td>\n",
              "      <td>1.541</td>\n",
              "      <td>1291</td>\n",
              "      <td>33</td>\n",
              "      <td>3.714</td>\n",
              "      <td>0.105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3418.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3418.0</td>\n",
              "      <td>2.594</td>\n",
              "      <td>1887</td>\n",
              "      <td>20</td>\n",
              "      <td>2.333</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Attrition_Flag  Customer_Age  ...  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio\n",
              "0               1            45  ...                1.625                  0.061\n",
              "1               1            49  ...                3.714                  0.105\n",
              "2               1            51  ...                2.333                  0.000\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c99jTSVF69od"
      },
      "source": [
        "x_data = data_df.drop(['Attrition_Flag'], axis=1)\n",
        "y_data = data_df['Attrition_Flag']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOIGbd-l7EYc"
      },
      "source": [
        "x_train, x_test, y_train, y_test =\\\n",
        "model_selection.train_test_split(x_data, y_data, test_size=0.3, random_state=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "19dupj0F7Hl4",
        "outputId": "0dcd3859-51d4-4d9d-b057-97a36a9d81b6"
      },
      "source": [
        "categorical_features = ['Card_Category', 'Education_Level', 'Gender', 'Income_Category', 'Marital_Status']\n",
        "categorical_transformer = OneHotEncoder(categories='auto') # categories='auto' : just for ignoring warning messages\n",
        "\n",
        "temp = list(data_df[data_df.columns.difference(categorical_features)].columns)\n",
        "temp.remove('Attrition_Flag')\n",
        "\n",
        "numeric_features = temp\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[ # List of (name, transformer, column(s))\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "\n",
        "preprocessor_pipe = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "preprocessor_pipe.fit(x_train)\n",
        "\n",
        "x_train_transformed = preprocessor_pipe.transform(x_train)\n",
        "x_test_transformed = preprocessor_pipe.transform(x_test)\n",
        "\n",
        "pd.DataFrame(x_train_transformed)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.748406</td>\n",
              "      <td>1.867430</td>\n",
              "      <td>-0.396875</td>\n",
              "      <td>-0.643042</td>\n",
              "      <td>-0.031516</td>\n",
              "      <td>0.503334</td>\n",
              "      <td>0.661574</td>\n",
              "      <td>0.382646</td>\n",
              "      <td>-0.072588</td>\n",
              "      <td>-0.248166</td>\n",
              "      <td>-0.528565</td>\n",
              "      <td>1.176519</td>\n",
              "      <td>-0.226807</td>\n",
              "      <td>0.065913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.465262</td>\n",
              "      <td>-0.136514</td>\n",
              "      <td>1.409288</td>\n",
              "      <td>-0.483890</td>\n",
              "      <td>0.465118</td>\n",
              "      <td>-1.042699</td>\n",
              "      <td>-1.355504</td>\n",
              "      <td>0.506545</td>\n",
              "      <td>-0.529711</td>\n",
              "      <td>-0.227189</td>\n",
              "      <td>1.413773</td>\n",
              "      <td>-0.203125</td>\n",
              "      <td>-0.602199</td>\n",
              "      <td>-0.686286</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.645385</td>\n",
              "      <td>-1.004532</td>\n",
              "      <td>-0.396875</td>\n",
              "      <td>-0.773617</td>\n",
              "      <td>-0.528149</td>\n",
              "      <td>0.503334</td>\n",
              "      <td>0.661574</td>\n",
              "      <td>-0.732443</td>\n",
              "      <td>-0.309941</td>\n",
              "      <td>-0.877476</td>\n",
              "      <td>0.766327</td>\n",
              "      <td>-1.419165</td>\n",
              "      <td>-0.445185</td>\n",
              "      <td>-0.937019</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.661164</td>\n",
              "      <td>-0.843788</td>\n",
              "      <td>-0.396875</td>\n",
              "      <td>0.603356</td>\n",
              "      <td>-0.900624</td>\n",
              "      <td>-0.269682</td>\n",
              "      <td>1.670113</td>\n",
              "      <td>-0.236848</td>\n",
              "      <td>-0.274777</td>\n",
              "      <td>-0.206212</td>\n",
              "      <td>1.413773</td>\n",
              "      <td>-0.647541</td>\n",
              "      <td>0.097591</td>\n",
              "      <td>0.776322</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.340494</td>\n",
              "      <td>-1.004532</td>\n",
              "      <td>0.506206</td>\n",
              "      <td>-0.468502</td>\n",
              "      <td>1.085910</td>\n",
              "      <td>-1.042699</td>\n",
              "      <td>1.670113</td>\n",
              "      <td>1.249938</td>\n",
              "      <td>0.498816</td>\n",
              "      <td>-0.420177</td>\n",
              "      <td>1.413773</td>\n",
              "      <td>-1.419165</td>\n",
              "      <td>-0.598166</td>\n",
              "      <td>-1.145963</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4951</th>\n",
              "      <td>1.505764</td>\n",
              "      <td>-0.697332</td>\n",
              "      <td>-0.396875</td>\n",
              "      <td>1.598057</td>\n",
              "      <td>-0.900624</td>\n",
              "      <td>-1.042699</td>\n",
              "      <td>-0.346965</td>\n",
              "      <td>-0.856342</td>\n",
              "      <td>-0.024239</td>\n",
              "      <td>-0.105522</td>\n",
              "      <td>1.413773</td>\n",
              "      <td>1.012916</td>\n",
              "      <td>-0.539970</td>\n",
              "      <td>-1.354907</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4952</th>\n",
              "      <td>-0.256693</td>\n",
              "      <td>-0.450858</td>\n",
              "      <td>0.506206</td>\n",
              "      <td>-0.283961</td>\n",
              "      <td>-0.155674</td>\n",
              "      <td>-0.269682</td>\n",
              "      <td>-0.346965</td>\n",
              "      <td>-1.351937</td>\n",
              "      <td>-1.290118</td>\n",
              "      <td>0.053903</td>\n",
              "      <td>-0.528565</td>\n",
              "      <td>-0.300799</td>\n",
              "      <td>-0.787158</td>\n",
              "      <td>-1.396696</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4953</th>\n",
              "      <td>-0.630997</td>\n",
              "      <td>0.642202</td>\n",
              "      <td>-0.396875</td>\n",
              "      <td>-0.609849</td>\n",
              "      <td>-1.645575</td>\n",
              "      <td>-1.042699</td>\n",
              "      <td>0.661574</td>\n",
              "      <td>0.010950</td>\n",
              "      <td>-0.081379</td>\n",
              "      <td>-1.066269</td>\n",
              "      <td>0.118881</td>\n",
              "      <td>0.240071</td>\n",
              "      <td>-0.683154</td>\n",
              "      <td>-0.686286</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4954</th>\n",
              "      <td>1.285004</td>\n",
              "      <td>-1.004532</td>\n",
              "      <td>0.506206</td>\n",
              "      <td>1.158190</td>\n",
              "      <td>0.713435</td>\n",
              "      <td>0.503334</td>\n",
              "      <td>-1.355504</td>\n",
              "      <td>1.373837</td>\n",
              "      <td>-1.527470</td>\n",
              "      <td>-1.666211</td>\n",
              "      <td>1.413773</td>\n",
              "      <td>-1.419165</td>\n",
              "      <td>-0.766991</td>\n",
              "      <td>-0.937019</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4955</th>\n",
              "      <td>-0.534236</td>\n",
              "      <td>-1.004532</td>\n",
              "      <td>0.506206</td>\n",
              "      <td>-0.662387</td>\n",
              "      <td>0.340960</td>\n",
              "      <td>-0.269682</td>\n",
              "      <td>0.661574</td>\n",
              "      <td>0.258747</td>\n",
              "      <td>1.285595</td>\n",
              "      <td>-0.139086</td>\n",
              "      <td>1.413773</td>\n",
              "      <td>-1.419165</td>\n",
              "      <td>-0.293070</td>\n",
              "      <td>-0.101243</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4956 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3         4   ...   29   30   31   32   33\n",
              "0    -0.748406  1.867430 -0.396875 -0.643042 -0.031516  ...  0.0  0.0  0.0  1.0  0.0\n",
              "1    -0.465262 -0.136514  1.409288 -0.483890  0.465118  ...  0.0  0.0  0.0  1.0  0.0\n",
              "2    -0.645385 -1.004532 -0.396875 -0.773617 -0.528149  ...  0.0  0.0  0.0  1.0  0.0\n",
              "3     0.661164 -0.843788 -0.396875  0.603356 -0.900624  ...  0.0  0.0  0.0  0.0  1.0\n",
              "4    -0.340494 -1.004532  0.506206 -0.468502  1.085910  ...  0.0  1.0  0.0  1.0  0.0\n",
              "...        ...       ...       ...       ...       ...  ...  ...  ...  ...  ...  ...\n",
              "4951  1.505764 -0.697332 -0.396875  1.598057 -0.900624  ...  1.0  0.0  0.0  0.0  1.0\n",
              "4952 -0.256693 -0.450858  0.506206 -0.283961 -0.155674  ...  0.0  1.0  0.0  1.0  0.0\n",
              "4953 -0.630997  0.642202 -0.396875 -0.609849 -1.645575  ...  1.0  0.0  0.0  1.0  0.0\n",
              "4954  1.285004 -1.004532  0.506206  1.158190  0.713435  ...  0.0  0.0  0.0  0.0  1.0\n",
              "4955 -0.534236 -1.004532  0.506206 -0.662387  0.340960  ...  0.0  1.0  0.0  1.0  0.0\n",
              "\n",
              "[4956 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8j7Bv3yblHa"
      },
      "source": [
        "x_train = x_train_transformed.astype('float32')\n",
        "x_test = x_test_transformed.astype('float32') "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_PSMzOKsPDJ",
        "outputId": "22495ed1-b2b1-4be2-e146-50475de8fd52"
      },
      "source": [
        "x_train_transformed.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4956, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2M1Op-Hb7uI"
      },
      "source": [
        "# 2) Build the hyper-model\n",
        "# Available HyperParameter search spaces (https://j.mp/2IXPzh7) : Int, Float, Boolean, Choice, Fixed\n",
        "\n",
        "def build_hyper_model(hp):\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    # model.add(layers.Dense(input_dim=34, units=64, activation='relu'))\n",
        "        \n",
        "    # Tune the number of hidden layer (Choose an optimal value between 1~3)\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=3)): \n",
        "        # Tune the number of perceptrons in a dense layer (Choose an optimal value between 32~512) \n",
        "        hp_units = hp.Int('units_' + str(i), min_value=32, max_value=512, step=32) # 32:512 & step 32, all parameter names should be unique (we name the inner parameters 'units_' + str(i))\n",
        "        hp_activations = hp.Choice('activation_' + str(i), values=['relu', 'elu'])\n",
        "        model.add(layers.Dense(units = hp_units, activation = hp_activations))\n",
        "\n",
        "    model.add(layers.Dense(10, activation='softmax')) # class 10 : 0~9\n",
        "\n",
        "    # Tune the learning rate for the optimizer (Choose an optimal value from 0.01, 0.001, or 0.0001)\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "    \n",
        "    model.compile(optimizer = optimizers.Adam(learning_rate = hp_learning_rate),\n",
        "                loss = losses.SparseCategoricalCrossentropy(), # use sparse c.c when our labels are looks like \"1\" (single integer), not \"[1,0,0]\" (one-hot vector) (@ http://j.mp/2XS0jmv)\n",
        "                metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa3OXBWtc3Wf",
        "outputId": "1401bcb2-03f3-4961-e463-fcddf90bbcac"
      },
      "source": [
        "# 3) Select tuner and compile it\n",
        "# Available tuners (https://j.mp/39cWz4n) : kt.BayesianOptimization / kt.Hyperband / kt.RandomSearch / kt.Sklearn (https://j.mp/3nSJn8O)\n",
        "\n",
        "tuner = kt.BayesianOptimization(build_hyper_model,\n",
        "                                objective = 'val_accuracy', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n",
        "                                max_trials = 10, # 서로 다른 Hyper-params 조합으로 시도할 총 Trial 횟수 설정\n",
        "                                directory = 'test_prac_dir', # Path to the working directory\n",
        "                                project_name = 'MNIST_hyper_1') # Name to use as directory name for files saved by this Tuner\n",
        "\n",
        "# tuner = kt.Hyperband(build_hyper_model,\n",
        "#                      objective = 'val_accuracy', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n",
        "#                      max_epochs = 5, # 최대 epoch 수 설정, epoch 수 자체도 지정한 최대 횟수 내에서 변화시켜가며 테스트를 진행함 (epochs to train one model) \n",
        "#                      directory = 'test_prac_dir', # Path to the working directory\n",
        "#                      project_name = 'MNIST_hyper_1') # Name to use as directory name for files saved by this Tuner\n",
        "\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "activation_0 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woRJd7mIdSSV",
        "outputId": "746c0689-2d11-4b99-f3fa-63219c11620c"
      },
      "source": [
        "# 4) Train the model\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data = (x_test, y_test)) # epochs == learning epoch for training a single model(epoch for each trial) \n",
        "\n",
        "\n",
        "# # 아래와 같이 별도의 클래스로 콜백을 정의하여 search 함수에서 활용하면 모든 학습 단계 종료 후 학습 중 발생한 출력 결과를 자동으로 지워낼 수 있습니다.\n",
        "# class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "#   def on_train_end(*args, **kwargs):\n",
        "#     IPython.display.clear_output(wait = True)\n",
        "\n",
        "# tuner.search(x_train, y_train, epochs = 7, validation_data = (x_test, y_test), callbacks = [ClearTrainingOutput()]) # epochs == learning epoch for training a single model "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 00m 05s]\n",
            "val_accuracy: 0.9317647218704224\n",
            "\n",
            "Best val_accuracy So Far: 0.9350588321685791\n",
            "Total elapsed time: 00h 01m 05s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDlJzL14GVXR",
        "outputId": "e3378d48-4f9c-4872-8329-b113ecd47c12"
      },
      "source": [
        "# 5) Check the result \n",
        "\n",
        "tuner.results_summary(num_trials=3) # Show \"n\" best trial results"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in test_prac_dir/MNIST_hyper_1\n",
            "Showing 3 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 32\n",
            "activation_0: relu\n",
            "learning_rate: 0.01\n",
            "units_1: 32\n",
            "activation_1: elu\n",
            "units_2: 512\n",
            "activation_2: elu\n",
            "Score: 0.9350588321685791\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 512\n",
            "activation_0: relu\n",
            "learning_rate: 0.001\n",
            "units_1: 320\n",
            "activation_1: elu\n",
            "units_2: 416\n",
            "activation_2: elu\n",
            "Score: 0.9345882534980774\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 512\n",
            "activation_0: relu\n",
            "learning_rate: 0.01\n",
            "units_1: 512\n",
            "activation_1: elu\n",
            "units_2: 512\n",
            "activation_2: relu\n",
            "Score: 0.9336470365524292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFbk0Bvo36HR",
        "outputId": "c207b6c7-d752-4d86-b530-b4cbe48cb11d"
      },
      "source": [
        "# Check top-3 trials' hyper-params\n",
        "\n",
        "top3_models = tuner.get_best_hyperparameters(num_trials=3)\n",
        "# print(tuner.get_best_hyperparameters(num_trials=3)[0].space) # 특정 Trial의 Search-space 를 확인할 수 있음\n",
        "# print(tuner.get_best_hyperparameters(num_trials=3)[0].values) # 특정 Trial에 적용된 Hyper-params를 확인할 수 있음\n",
        "\n",
        "for idx, model in enumerate(top3_models):\n",
        "    print('Model performance rank :', idx)\n",
        "    print(model.values)\n",
        "    print()\n",
        "\n",
        "\n",
        "# Check the best trial's hyper-params\n",
        "\n",
        "best_hps = top3_models[0]\n",
        "\n",
        "print(\"\"\"\n",
        "The hyperparameter search is complete. \n",
        "* Optimal # of layers : {}\n",
        "* Optimal value of the learning-rate : {}\"\"\".format(best_hps.get('num_layers'), best_hps.get('learning_rate')))\n",
        "\n",
        "for layer_num in range(best_hps.get('num_layers')):\n",
        "    print('Layer {} - # of Perceptrons :'.format(layer_num), best_hps.get('units_' + str(layer_num)))\n",
        "    print('Layer {} - Applied activation function :'.format(layer_num), best_hps.get('activation_' + str(layer_num)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance rank : 0\n",
            "{'num_layers': 1, 'units_0': 32, 'activation_0': 'relu', 'learning_rate': 0.01, 'units_1': 32, 'activation_1': 'elu', 'units_2': 512, 'activation_2': 'elu'}\n",
            "\n",
            "Model performance rank : 1\n",
            "{'num_layers': 1, 'units_0': 512, 'activation_0': 'relu', 'learning_rate': 0.001, 'units_1': 320, 'activation_1': 'elu', 'units_2': 416, 'activation_2': 'elu'}\n",
            "\n",
            "Model performance rank : 2\n",
            "{'num_layers': 1, 'units_0': 512, 'activation_0': 'relu', 'learning_rate': 0.01, 'units_1': 512, 'activation_1': 'elu', 'units_2': 512, 'activation_2': 'relu'}\n",
            "\n",
            "\n",
            "The hyperparameter search is complete. \n",
            "* Optimal # of layers : 1\n",
            "* Optimal value of the learning-rate : 0.01\n",
            "Layer 0 - # of Perceptrons : 32\n",
            "Layer 0 - Applied activation function : relu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzjYRGC_1MGu",
        "outputId": "cf9e57a5-7336-4cf6-8312-7d7dc2353751"
      },
      "source": [
        "print(best_models[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f7510280c90>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j5xYX3dOHqV",
        "outputId": "ad00366f-5347-430c-c7fe-46d66e118b05"
      },
      "source": [
        "# We can retrain the model with the optimal hyperparameters from the search.\n",
        "best_hps = top3_models[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters and train it on the data.\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.fit(x_train_transformed, y_train, epochs=10, validation_data=(x_test_transformed, y_test))\n",
        "\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print('Cross-entropy :', results[0])\n",
        "print('Accuracy :', results[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8789 - val_loss: 0.2317 - val_accuracy: 0.9049\n",
            "Epoch 2/10\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9189 - val_loss: 0.1957 - val_accuracy: 0.9181\n",
            "Epoch 3/10\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9290 - val_loss: 0.1817 - val_accuracy: 0.9247\n",
            "Epoch 4/10\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9332 - val_loss: 0.1873 - val_accuracy: 0.9200\n",
            "Epoch 5/10\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9344 - val_loss: 0.1782 - val_accuracy: 0.9256\n",
            "Epoch 6/10\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9368 - val_loss: 0.1788 - val_accuracy: 0.9313\n",
            "Epoch 7/10\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9441 - val_loss: 0.1820 - val_accuracy: 0.9294\n",
            "Epoch 8/10\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9435 - val_loss: 0.2004 - val_accuracy: 0.9219\n",
            "Epoch 9/10\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9463 - val_loss: 0.1928 - val_accuracy: 0.9214\n",
            "Epoch 10/10\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9457 - val_loss: 0.1717 - val_accuracy: 0.9294\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9294\n",
            "Cross-entropy : 0.17171938717365265\n",
            "Accuracy : 0.929411768913269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzDjBlGg2Lx5",
        "outputId": "3bc1502e-bf91-4189-956d-65344fe292ba"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                1120      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 1,450\n",
            "Trainable params: 1,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N53W-VP4X_6Y",
        "outputId": "363d1976-b6d7-4e34-fae5-1eeded445933"
      },
      "source": [
        "# We can also find detailed logs, checkpoints, etc, in the folder \"directory/project_name\".\n",
        "\n",
        "# The [test_prac_dir/MNIST_hyper_1] directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. \n",
        "# If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. \n",
        "# To disable this behavior, pass an additional [overwrite = True] argument while instantiating the tuner.\n",
        "\n",
        "for trial in tuner.oracle.get_best_trials(num_trials=3):\n",
        "    print('Trial-score is :', trial.score)\n",
        "    print('Trial-directory(trial_id) is :', trial.trial_id)\n",
        "    print()\n",
        "\n",
        "# tuner.oracle.trials -> get all trial_id "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial-score is : 0.9350588321685791\n",
            "Trial-directory(trial_id) is : c4d62457511638f3107db517044a3cf5\n",
            "\n",
            "Trial-score is : 0.9345882534980774\n",
            "Trial-directory(trial_id) is : 986a0a7674e5f3a01883604341d7431e\n",
            "\n",
            "Trial-score is : 0.9336470365524292\n",
            "Trial-directory(trial_id) is : 0217c25a4f2de0f6606b11cb844759d9\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}